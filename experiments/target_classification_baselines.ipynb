{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from text_util import strip_accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(13)\n",
    "torch.manual_seed(13)\n",
    "np.random.seed(13)\n",
    "torch.backends.cudnn.benchmarks = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "device = torch.device('cuda:0')\n",
    "plm_names = ['bert-base-uncased', 'bert-large-uncased', 'roberta-base', 'roberta-large', 'xlnet-large-cased', 'facebook/bart-large']\n",
    "plm_name = plm_names[2]\n",
    "plm_dim = 1024 if 'large' in plm_name else 768\n",
    "model_names = ['basiccontext', 'sanitycheck', 'nocontext', 'userbiocontext', 'wikicontext', 'parcontext', 'parcontext-partial']\n",
    "model_num = model_names[2]\n",
    "num_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpath = '/homes/rpujari/scratch0_ml/tweet_target_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tpath + 'annotated_data_dict.pkl', 'rb') as infile:\n",
    "    data_dict = pickle.load(infile)\n",
    "with open(tpath + 'target_task_data_examples_v7.json', 'r') as infile:\n",
    "    data_examples = json.load(infile)\n",
    "with open(tpath + 'target_task_split_v7.json', 'r') as infile:\n",
    "    data_split = json.load(infile)\n",
    "with open(tpath + 'us_politicians.pkl', 'rb') as infile:\n",
    "    politician_dict = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5890\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for tlink in data_examples:\n",
    "    c += len(data_examples[tlink])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069\n",
      "torch.Size([1069, 512])\n"
     ]
    }
   ],
   "source": [
    "handler_mapping = dict()\n",
    "for p_id in politician_dict:\n",
    "    for cg_year in politician_dict[p_id]:\n",
    "        handler = politician_dict[p_id][cg_year]['twitter_account']\n",
    "        fqn = politician_dict[p_id][cg_year]['first_name'] + ' ' + politician_dict[p_id][cg_year]['last_name']\n",
    "        fqn = strip_accents(fqn)\n",
    "        if handler not in handler_mapping:\n",
    "            handler_mapping[handler] = fqn\n",
    "            \n",
    "# Load PAR Embeddings\n",
    "par_ent_list = [l.strip() for l in open(tpath + 'PAR/political_actor_reps/entity_list.txt').readlines() if l.strip()]\n",
    "print(len(par_ent_list))\n",
    "part_embs = torch.load(tpath + 'PAR/political_actor_reps/learned_reps.pt')\n",
    "print(part_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tpath + 'author_name_embeddings/author_name_embeddings_' + plm_name.replace('/', '_') + '.pkl', 'rb') as infile:\n",
    "    author_name_embs = pickle.load(infile)\n",
    "with open(tpath + 'user_description_embeddings/user_description_embeddings_' + plm_name.replace('/', '_') + '.pkl', 'rb') as infile:\n",
    "    user_description_embs = pickle.load(infile)\n",
    "with open(tpath + 'target_name_embeddings/target_name_embeddings_7.0_' + plm_name.replace('/', '_') + '.pkl', 'rb') as infile:\n",
    "    target_name_embs = pickle.load(infile)\n",
    "with open(tpath + 'event_name_embeddings/event_name_embeddings_' + plm_name.replace('/', '_') + '.pkl', 'rb') as infile:\n",
    "    event_name_embs = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129639\n"
     ]
    }
   ],
   "source": [
    "fnames = sorted([f for f in os.listdir(tpath + 'wiki_pages_7.0/') if not (f.endswith('.parse') or f.endswith('.pkl'))])\n",
    "\n",
    "all_sents = []\n",
    "sent_id_dict = {}\n",
    "rev_sent_id_dict = {}\n",
    "\n",
    "i = 0\n",
    "for fname in fnames:\n",
    "    ftext = sent_tokenize(open(tpath + 'wiki_pages_7.0/' + fname).read().strip())\n",
    "    rev_sent_id_dict[fname] = []\n",
    "    for sent in ftext:\n",
    "        urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', sent)\n",
    "        for url in urls:\n",
    "            sent = sent.replace(url, '')\n",
    "        all_sents.append(sent)\n",
    "        sent_id_dict[i] = fname\n",
    "        rev_sent_id_dict[fname].append(i)\n",
    "        i += 1\n",
    "\n",
    "data_tlinks = sorted(list(data_dict.keys()))\n",
    "for tlink in data_tlinks:\n",
    "    ttext = data_dict[tlink]['text']\n",
    "    urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', ttext)\n",
    "    for url in urls:\n",
    "        ttext = ttext.replace(url, '')\n",
    "    all_sents.append(ttext)    \n",
    "    sent_id_dict[i] = tlink\n",
    "    rev_sent_id_dict[tlink] = [i]\n",
    "    i += 1\n",
    "\n",
    "print(len(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tpath + 'target_sentiment_embeddings/target_sentiment_7.0_all_embs_' + plm_name.replace('/', '_') + '.pkl', 'rb') as infile:\n",
    "    all_embs = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129639, 768])\n"
     ]
    }
   ],
   "source": [
    "all_embs = torch.from_numpy(all_embs).type(torch.FloatTensor)\n",
    "print(all_embs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_embs = {}\n",
    "for fname in fnames:\n",
    "    fsent_embs = [all_embs[i:i+1, :] for i in rev_sent_id_dict[fname]]\n",
    "    file_emb = torch.sum(torch.cat(fsent_embs, dim=0), dim=0)\n",
    "    file_embs[fname] = file_emb.numpy().reshape(1, -1)\n",
    "    \n",
    "for tlink in data_dict.keys():\n",
    "    data_dict[tlink]['tweet_emb'] = all_embs[rev_sent_id_dict[tlink][0]].numpy().reshape(1, -1)\n",
    "    \n",
    "for tlink in data_dict:\n",
    "    eg = data_dict[tlink]\n",
    "    file_embs[eg['text']] = eg['tweet_emb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_wiki = {\n",
    "    'capitol': 'https://en.wikipedia.org/wiki/2021_United_States_Capitol_attack',\n",
    "    'blm': 'https://en.wikipedia.org/wiki/George_Floyd_protests',\n",
    "    'lasvegas': 'https://en.wikipedia.org/wiki/2017_Las_Vegas_shooting',\n",
    "    'borderwall': 'https://en.wikipedia.org/wiki/Trump_wall',\n",
    "    'kavanugh': 'https://en.wikipedia.org/wiki/Brett_Kavanaugh_Supreme_Court_nomination',\n",
    "    'elpaso': 'https://en.wikipedia.org/wiki/2019_El_Paso_shooting'\n",
    "}\n",
    "\n",
    "rev_event_wiki = {}\n",
    "for event in event_wiki:\n",
    "    rev_event_wiki[event_wiki[event]] = event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tensor Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_arrays(data_examples):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "\n",
    "    data_tlinks = sorted(list(data_examples.keys()))\n",
    "    wiki_count = 0\n",
    "\n",
    "    for tlink in data_tlinks:\n",
    "        #read example from data_dict\n",
    "        eg = data_dict[tlink]\n",
    "        sel_eg = True\n",
    "\n",
    "        #nocontext mode means embeddings come from PLM embedding of the name strings\n",
    "        if model_num == 'nocontext' or model_num == 'basiccontext':\n",
    "            author_emb = torch.from_numpy(author_name_embs[tlink].reshape(-1)).type(torch.FloatTensor) #model-0\n",
    "            event_emb = torch.from_numpy(event_name_embs[eg['event']].reshape(-1)).type(torch.FloatTensor) #model-0\n",
    "\n",
    "        #userbiocontext -> author embeddings from author's twitter bio\n",
    "        elif model_num == 'userbiocontext':\n",
    "            author_emb = torch.from_numpy(user_description_embs[tlink].reshape(-1)).type(torch.FloatTensor) #model-1\n",
    "            event_emb = torch.from_numpy(event_name_embs[eg['event']].reshape(-1)).type(torch.FloatTensor) #model-1\n",
    "\n",
    "        #wikicontext -> author and event embeddings come from their respective wikipedia pages\n",
    "        elif model_num == 'wikicontext':\n",
    "            author_emb = torch.from_numpy(file_embs[eg['author']].reshape(-1)).type(torch.FloatTensor) #model-2\n",
    "            event_emb = torch.from_numpy(file_embs[rev_event_wiki[eg['event']]].reshape(-1)).type(torch.FloatTensor) #model-2\n",
    "\n",
    "        #parcontext-partial -> author embeddings come from PAR model, event embeddings from wikipedia pages\n",
    "        #parcontext -> use wiki page embedding for missing authors\n",
    "        elif model_num == 'parcontext' or model_num == 'parcontext-partial':\n",
    "            if eg['author'][1:] in handler_mapping:\n",
    "                real_name = handler_mapping[eg['author'][1:]]\n",
    "                if real_name.lower() in par_ent_list:\n",
    "                    author_emb = part_embs[par_ent_list.index(real_name.lower()), :]\n",
    "                else:\n",
    "                    if model_num == 'parcontext-partial':\n",
    "                        sel_eg = False\n",
    "                    author_emb = torch.from_numpy(file_embs[eg['author']].reshape(-1)[:512]).type(torch.FloatTensor) #model-2\n",
    "                    wiki_count += 1\n",
    "            else:\n",
    "                if model_num == 'parcontext-partial':\n",
    "                    sel_eg = False\n",
    "                author_emb = torch.from_numpy(file_embs[eg['author']].reshape(-1)[:512]).type(torch.FloatTensor) #model-2\n",
    "                wiki_count += 1\n",
    "            event_emb = torch.from_numpy(file_embs[rev_event_wiki[eg['event']]].reshape(-1)).type(torch.FloatTensor) #model-2\n",
    "\n",
    "        tweet_emb = torch.from_numpy(eg['tweet_emb'].reshape(-1)).type(torch.FloatTensor)\n",
    "\n",
    "        for eg in data_examples[tlink]:\n",
    "            if model_num == 'nocontext' or model_num == 'userbiocontext' or model_num == 'sanitycheck' or model_num == 'basiccontext': \n",
    "                ann_emb = torch.from_numpy(target_name_embs[eg['choice']].reshape(-1)).type(torch.FloatTensor) #model-0/model-1\n",
    "            elif model_num == 'wikicontext' or model_num == 'parcontext' or model_num == 'parcontext-partial' :\n",
    "                ann_emb = torch.from_numpy(file_embs[eg['choice']].reshape(-1)).type(torch.FloatTensor) #model-2\n",
    "            if sel_eg:\n",
    "                if model_num == 'sanitycheck':\n",
    "                    data_x.append((ann_emb))\n",
    "                elif model_num == 'basiccontext':\n",
    "                    data_x.append((tweet_emb, ann_emb))\n",
    "                else:\n",
    "                    data_x.append((author_emb, event_emb, tweet_emb, ann_emb))\n",
    "                data_y.append(torch.tensor(np.array([int(eg['label'])])))\n",
    "\n",
    "    print(len(data_x))\n",
    "    if model_num == 'parcontext' or model_num == 'parcontext-partial':\n",
    "        print(wiki_count)\n",
    "        \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_x, data_y = get_data_arrays(data_examples)\n",
    "\n",
    "# data_inds = list(range(len(data_x)))\n",
    "# random.shuffle(data_inds)a\n",
    "# # print(data_inds)\n",
    "# data_x = [data_x[i] for i in data_inds]\n",
    "# data_y = [data_y[i] for i in data_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = []\n",
    "\n",
    "# for i in range(num_folds):\n",
    "#     folds.append(([], []))\n",
    "    \n",
    "# for x, y in zip(data_x, data_y):\n",
    "#     fnum = int(np.floor(random.random() * num_folds))\n",
    "#     if model_num == 'sanitycheck':\n",
    "#         folds[fnum][0].append(x.unsqueeze(0))\n",
    "#     else:\n",
    "#         folds[fnum][0].append(torch.cat(list(x), dim=0).unsqueeze(0))\n",
    "#     folds[fnum][1].append(y)\n",
    "    \n",
    "# tensor_data = []\n",
    "# for i in range(num_folds):\n",
    "#     fold_inds = list(range(len(folds[i][0])))\n",
    "#     random.shuffle(fold_inds)\n",
    "#     # print(fold_inds, '\\n')\n",
    "#     fold_x = [folds[i][0][j] for j in fold_inds]\n",
    "#     fold_y = [folds[i][1][j] for j in fold_inds]\n",
    "#     # print(fold_x[0].shape)\n",
    "#     tensor_data.append((torch.cat(fold_x, dim=0), torch.cat(fold_y, dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tensor_data[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4370\n",
      "511\n",
      "1009\n"
     ]
    }
   ],
   "source": [
    "tr_data_x, tr_data_y = get_data_arrays(data_split['train'])\n",
    "de_data_x, de_data_y = get_data_arrays(data_split['dev'])\n",
    "te_data_x, te_data_y = get_data_arrays(data_split['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inds = list(range(len(tr_data_x)))\n",
    "random.shuffle(data_inds)\n",
    "\n",
    "tr_data_x = [tr_data_x[i] for i in data_inds]\n",
    "tr_data_y = [tr_data_y[i] for i in data_inds]\n",
    "\n",
    "#train_tensor creation\n",
    "tr_data = ([], [])\n",
    "for x, y in zip(tr_data_x, tr_data_y):\n",
    "    if model_num == 'sanitycheck':\n",
    "        tr_data[0].append(x.unsqueeze(0))\n",
    "    else:\n",
    "        tr_data[0].append(torch.cat(list(x), dim=0).unsqueeze(0))\n",
    "    tr_data[1].append(y)\n",
    "\n",
    "tr_tensor = (torch.cat(tr_data[0], dim=0), torch.cat(tr_data[1], dim=0))\n",
    "\n",
    "#dev_tensor creation\n",
    "de_data = ([], [])\n",
    "for x, y in zip(de_data_x, de_data_y):\n",
    "    if model_num == 'sanitycheck':\n",
    "        de_data[0].append(x.unsqueeze(0))\n",
    "    else:\n",
    "        de_data[0].append(torch.cat(list(x), dim=0).unsqueeze(0))\n",
    "    de_data[1].append(y)\n",
    "\n",
    "de_tensor = (torch.cat(de_data[0], dim=0), torch.cat(de_data[1], dim=0))\n",
    "\n",
    "#test_tensor creation\n",
    "te_data = ([], [])\n",
    "for x, y in zip(te_data_x, te_data_y):\n",
    "    if model_num == 'sanitycheck':\n",
    "        te_data[0].append(x.unsqueeze(0))\n",
    "    else:\n",
    "        te_data[0].append(torch.cat(list(x), dim=0).unsqueeze(0))\n",
    "    te_data[1].append(y)\n",
    "\n",
    "te_tensor = (torch.cat(te_data[0], dim=0), torch.cat(te_data[1], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tensor = {\n",
    "    'train': tr_tensor,\n",
    "    'dev': de_tensor,\n",
    "    'test': te_tensor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, sizes, use_cuda, lr, momentum, weight_decay, loss_weight):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.layers = []\n",
    "        i = 0\n",
    "        for s1, s2 in zip(sizes[:-1], sizes[1:]):\n",
    "            self.layers.append(nn.Linear(s1, s2))\n",
    "            self.register_parameter('weight-layer-' + str(i), self.layers[-1].weight)\n",
    "            self.register_parameter('bias-layer-' + str(i), self.layers[-1].bias)\n",
    "            nn.init.xavier_uniform_(self.layers[-1].weight)\n",
    "            i += 1\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "        self.nl = nn.Tanh()\n",
    "        params = [p for p in self.parameters() if p.requires_grad]\n",
    "        self.optimizer = optim.Adam(params, lr=lr)\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.nl(layer(x))\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out\n",
    "        \n",
    "    def evaluate(self, data):\n",
    "        self.eval()\n",
    "        batch_outs = []\n",
    "        batch_preds = []\n",
    "        batch_ys = []\n",
    "        for batch_x, batch_y in data:\n",
    "            if self.use_cuda:\n",
    "                batch_x = batch_x.cuda(device)\n",
    "                batch_y = batch_y.cuda(device)\n",
    "            batch_out = self.forward(batch_x)\n",
    "            batch_pred = torch.argmax(batch_out, dim=1)\n",
    "            batch_outs.append(batch_out)\n",
    "            batch_preds.append(batch_pred)\n",
    "            batch_ys.append(batch_y)\n",
    "        pred_y = torch.cat(batch_preds, dim=0)\n",
    "        data_y = torch.cat(batch_ys, dim=0)\n",
    "        pred_out = torch.cat(batch_outs, dim=0)\n",
    "        acc = sum((pred_y == data_y).float()) / data_y.size(0)\n",
    "        f1_mi = f1_score(data_y.cpu().data, pred_y.cpu().data, average='micro')\n",
    "        f1_ma = f1_score(data_y.cpu().data, pred_y.cpu().data, average='macro')\n",
    "        con_mat = confusion_matrix(data_y.cpu().data, pred_y.cpu().data)\n",
    "        val_loss = self.loss_fn(pred_out, data_y)\n",
    "        return float(acc.cpu().numpy()), float(val_loss.cpu().detach().numpy()), (f1_mi, f1_ma, [[int(x) for x in list(con_mat[0])], [int(x) for x in list(con_mat[1])]]), pred_y\n",
    "        \n",
    "    def train_model(self, train, val, num_epochs=25, save_path='./model.pkl', dev_benchmark=None):\n",
    "        self.train()\n",
    "        if dev_benchmark:\n",
    "            max_val = dev_benchmark[2][1]\n",
    "        else:\n",
    "            max_val = -1\n",
    "        for i in range(num_epochs):\n",
    "            for batch_x, batch_y in train:\n",
    "                if self.use_cuda:\n",
    "                    batch_x = batch_x.cuda(device)\n",
    "                    batch_y = batch_y.cuda(device)\n",
    "                ids = list(range(batch_x.size(0)))\n",
    "                # random.shuffle(ids)\n",
    "                batch_x = batch_x[ids, :]\n",
    "                batch_y = batch_y[ids]\n",
    "                batch_out = self.forward(batch_x)\n",
    "                loss = self.loss_fn(batch_out, batch_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            val_acc, val_loss, (f1_mi, f1_ma, cm), _ = self.evaluate(val)\n",
    "            if f1_ma > max_val:\n",
    "                max_val = f1_ma\n",
    "                torch.save(self.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_data(data, bsz=8):\n",
    "    dlen = data[0].size(0)\n",
    "    beg = 0\n",
    "    end = bsz\n",
    "    data_batches = []\n",
    "    while beg < dlen:\n",
    "        data_batches.append((data[0][beg:end, :], data[1][beg:end]))\n",
    "        beg += bsz\n",
    "        end += bsz\n",
    "    return data_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(data, args, k=10, num_epochs=25):\n",
    "    performance = []\n",
    "    for i in range(k):\n",
    "        test_data = batchify_data(data[i])\n",
    "        val_data = batchify_data(data[(i + 1) % k])\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        \n",
    "        for j in range(k):\n",
    "            if j != i and j != (i + 1) % k:\n",
    "                train_x.append(data[j][0])\n",
    "                train_y.append(data[j][1])\n",
    "        \n",
    "        train_X = torch.cat(train_x, dim=0)\n",
    "        train_Y = torch.cat(train_y, dim=0)\n",
    "        train_data = batchify_data((train_X, train_Y))\n",
    "        \n",
    "        label_loss_weight = train_Y.size(0) / torch.bincount(train_Y)\n",
    "        label_loss_weight = label_loss_weight / torch.sum(label_loss_weight)\n",
    "        args.loss_weight = label_loss_weight\n",
    "        \n",
    "        print(args.loss_weight)\n",
    "        model = FeedForward(args.sizes, args.use_cuda, args.lr, args.momentum, args.weight_decay, args.loss_weight)\n",
    "        model.cuda(device)\n",
    "        model.train_model(train_data, val_data, num_epochs, save_path='/homes/rpujari/scratch0_ml/trained_models/trained_params/baseline-model-7.0-' + str(model_num) + '-' + plm_name.replace('/', '_') + '-fold-' + str(i) + '.pkl')\n",
    "        model.load_state_dict(torch.load('/homes/rpujari/scratch0_ml/trained_models/trained_params/baseline-model-7.0-' + str(model_num) + '-' + plm_name.replace('/', '_') + '-fold-' + str(i)  + '.pkl'))\n",
    "        performance.append(model.evaluate(test_data))\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_experiments(data, args, num_epochs=25):\n",
    "    performance = {}\n",
    "    train_fold = data['train']\n",
    "    val_fold = data['dev']\n",
    "    test_fold = data['test']\n",
    "    \n",
    "    train_data = batchify_data(train_fold)\n",
    "    val_data = batchify_data(val_fold)\n",
    "    test_data = batchify_data(test_fold)\n",
    "    \n",
    "    label_loss_weight = train_fold[1].size(0) / torch.bincount(train_fold[1])\n",
    "    label_loss_weight = label_loss_weight / torch.sum(label_loss_weight)\n",
    "    args.loss_weight = label_loss_weight\n",
    "    print(args.loss_weight)\n",
    "    \n",
    "    model = FeedForward(args.sizes, args.use_cuda, args.lr, args.momentum, args.weight_decay, args.loss_weight)\n",
    "    model.to(device)\n",
    "    model.train_model(train_data, val_data, num_epochs, save_path='/homes/rpujari/scratch0_ml/trained_models/trained_params/baseline-split-7.0-' + str(model_num) + '-' + plm_name.replace('/', '_') + '.pkl')\n",
    "    model.load_state_dict(torch.load('/homes/rpujari/scratch0_ml/trained_models/trained_params/baseline-split-7.0-' + str(model_num) + '-' + plm_name.replace('/', '_') + '.pkl'))\n",
    "    \n",
    "    performance['train'] = model.evaluate(train_data)\n",
    "    performance['dev'] = model.evaluate(val_data)\n",
    "    performance['test'] = model.evaluate(test_data)\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_inference(data, args):\n",
    "    performance = {}\n",
    "    train_fold = data['train']\n",
    "    val_fold = data['dev']\n",
    "    test_fold = data['test']\n",
    "    \n",
    "    train_data = batchify_data(train_fold)\n",
    "    val_data = batchify_data(val_fold)\n",
    "    test_data = batchify_data(test_fold)\n",
    "    \n",
    "    label_loss_weight = train_fold[1].size(0) / torch.bincount(train_fold[1])\n",
    "    label_loss_weight = label_loss_weight / torch.sum(label_loss_weight)\n",
    "    args.loss_weight = label_loss_weight\n",
    "    print(args.loss_weight)\n",
    "    \n",
    "    model = FeedForward(args.sizes, args.use_cuda, args.lr, args.momentum, args.weight_decay, args.loss_weight)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('/homes/rpujari/scratch0_ml/trained_models/trained_params/baseline-split-7.0-' + str(model_num) + '-' + plm_name.replace('/', '_') + '.pkl', map_location=device))\n",
    "    \n",
    "    performance['train'] = model.evaluate(train_data)\n",
    "    performance['dev'] = model.evaluate(val_data)\n",
    "    performance['test'] = model.evaluate(test_data)\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        if model_num == 'parcontext' or model_num == 'parcontext-partial':\n",
    "            self.sizes = [512 + 3 * plm_dim, 1000, 2]\n",
    "        elif model_num == 'sanitycheck':\n",
    "            self.sizes = [plm_dim, 1000, 2]\n",
    "        elif model_num == 'basiccontext':\n",
    "            self.sizes = [2 * plm_dim, 1000, 2]\n",
    "        else:\n",
    "            self.sizes = [4 * plm_dim, 1000, 2]\n",
    "        self.use_cuda = True\n",
    "        self.lr = 1e-5\n",
    "        self.momentum = 0\n",
    "        self.weight_decay = 0\n",
    "        self.loss_weight = torch.tensor(np.array([0.5, 0.5]))\n",
    "        \n",
    "args1 = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5515, 0.4485])\n",
      "0:00:03.115977\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "# res = k_fold_cv(tensor_data, args1, k=num_folds, num_epochs=75)\n",
    "# res = train_test_experiments(split_tensor, args1, num_epochs=100)\n",
    "res = train_test_inference(split_tensor, args1)\n",
    "t2 = datetime.now()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_log = '../result_logs/baseline-split-7.0-' + str(model_num) + '-' +  plm_name.replace('/', '-') + '.log'\n",
    "# result_log = open(result_log, 'w')\n",
    "\n",
    "# f1_mas = [res[r1][2][1] for r1 in res]\n",
    "# for key in res:\n",
    "#     r1 = res[key]\n",
    "#     cmat = np.array(r1[2][2])\n",
    "#     prec = cmat[1, 1] / (cmat[1, 1] + cmat[0, 1])\n",
    "#     rec = cmat[1, 1] / (cmat[1, 1] + cmat[1, 0])\n",
    "#     acc = (cmat[1, 1] + cmat[0, 0]) / (cmat[0, 0] + cmat[0, 1] + cmat[1, 0] + cmat[1, 1])\n",
    "#     result_log.write(key + '\\n')\n",
    "#     result_log.write('Precision: ' + str(round(prec * 100, 2))  + '\\n')\n",
    "#     result_log.write('Recall: ' + str(round(rec * 100, 2)) + '\\n')\n",
    "#     result_log.write('F1: ' + str(round(r1[2][1] * 100, 2)) + '\\n')\n",
    "#     result_log.write('Accuracy: ' + str(round(acc * 100, 2)) + '\\n\\n')\n",
    "#     result_log.write('Confusion Matrix:\\n')\n",
    "#     result_log.write(str(r1[2][2]))\n",
    "#     result_log.write('\\n\\n')\n",
    "    \n",
    "# result_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "res_test = res['test'][-1]\n",
    "i = 0\n",
    "out_file = 'baseline-split-7.0-' + plm_name.replace('/', '_') + '-' + str(model_num) + '-hr-output.json'\n",
    "predidction_human = {}\n",
    "for tlink in data_split['test']:\n",
    "    predidction_human[tlink] = []\n",
    "    for ann in data_split['test'][tlink]:\n",
    "        hr_ann = copy.deepcopy(ann)\n",
    "        hr_ann['prediction'] = int(res_test[i].data)\n",
    "        predidction_human[tlink].append(hr_ann)\n",
    "        i += 1\n",
    "        \n",
    "json.dump(predidction_human, open(tpath + 'human_readable_outputs/' + out_file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_log = '../result_logs/baseline-model-6.0-' + str(model_num) + '-' +  plm_name.replace('/', '-') + '.log'\n",
    "# result_log = open(result_log, 'w')\n",
    "\n",
    "# f1_mas = [r1[2][1] for r1 in res]\n",
    "# for i, r1 in enumerate(res):\n",
    "#     result_log.write('Fold-' + str(i) + ' Mac-F1:')\n",
    "#     result_log.write(str(round(r1[2][1] * 100, 2)))\n",
    "#     result_log.write('\\n\\n')\n",
    "#     result_log.write('Fold-' + str(i) + ' Confusion Matrix:\\n')\n",
    "#     result_log.write(str(r1[2][2]))\n",
    "#     result_log.write('\\n\\n')\n",
    "# result_log.write('Macro-F1:')\n",
    "# result_log.write(str(round(np.mean(f1_mas) * 100, 2)))\n",
    "# result_log.write('\\n\\n')\n",
    "\n",
    "# precs = []\n",
    "# accs = []\n",
    "# recs = []\n",
    "# for r1 in res:\n",
    "#     cmat = np.array(r1[2][2])\n",
    "#     prec = cmat[1, 1] / (cmat[1, 1] + cmat[0, 1])\n",
    "#     rec = cmat[1, 1] / (cmat[1, 1] + cmat[1, 0])\n",
    "#     acc = (cmat[1, 1] + cmat[0, 0]) / (cmat[0, 0] + cmat[0, 1] + cmat[1, 0] + cmat[1, 1])\n",
    "#     precs.append(prec)\n",
    "#     accs.append(acc)\n",
    "#     recs.append(rec)\n",
    "# result_log.write('Precision:')\n",
    "# result_log.write(str(round(np.mean(precs) * 100, 2)))\n",
    "# result_log.write('\\n\\n')\n",
    "# result_log.write('Recall:')\n",
    "# result_log.write(str(round(np.mean(recs) * 100, 2)))\n",
    "# result_log.write('\\n\\n')\n",
    "# result_log.write('Accuracy:')\n",
    "# result_log.write(str(round(np.mean(accs) * 100, 2)))\n",
    "# result_log.write('\\n\\n')\n",
    "# result_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
